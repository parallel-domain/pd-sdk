{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5700eb87-5484-45a2-add6-5fdb2f22cbb4",
   "metadata": {},
   "source": [
    "# Color Matching Image Style Transfer\n",
    "CNNs tend to be sensitive to changes in input color distributions between training and target domains. Since images created by PD and those of many cameras differ in saturation and color distribution, we want a way of aligning those. Style transfer methods like GANs often hallucinate artifacts or add high frequency noise. We want to have an approach of aligning color spaces in a deterministic way, that won't change to content.\n",
    "\n",
    "The Image Style Transfer technique we reference to as Color Matching is based of [this Paper by Erik Reinhard](https://www.cs.tau.ac.il/~turkel/imagepapers/ColorTransfer.pdf). It approximates the color distributions of the source and target domain using channel wise gaussian distribution. It then computes an Affine Transformation between the source and target distributions. Applying the transformation to images transfers them from the source domain to the target domain.\n",
    "\n",
    "In most cases we want to transfer the synthetic images closer to the real world domain, so the source color distribution is the distribution of the synthetic images, the target distribution is the color distribution of th real camera images.\n",
    "\n",
    "| | original | transformed |\n",
    "|---|---|---|\n",
    "| PD Image | ![PD Highway](../../_static/color_matcher_pd_highway.png) |   |\n",
    "| Image from [Cityscapes](https://ieeexplore.ieee.org/document/7780719) | ![Cityscapes](../../_static/color_matcher_cityscapes.png) | ![PD Cityscapes](../../_static/color_matcher_pd_highway_cityscapes.png) |\n",
    "| Image from [Nuscenes](https://arxiv.org/abs/1903.11027) | ![Nuscenes](../../_static/color_matcher_nuscenes.jpeg) | ![PD Nuscenes](../../_static/color_matcher_pd_highway_nuscenes.png) |\n",
    "\n",
    "## Usage\n",
    "\n",
    "The main factor determining the quality of results is using representative color statistics. The usage therefore often has two steps: Calculation of the statistics and applying the statistics to the whole dataset. You can also calculate the color distribution on your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed943550-5bb0-49c6-a166-73bc4816d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paralleldomain.utilities.color_matcher import ColorMatcher, GaussianColorDistribution\n",
    "\n",
    "source_distribution = GaussianColorDistribution.from_folder(image_folder=\"path/to/a/folder/with/images\")\n",
    "target_distribution = GaussianColorDistribution.from_dataset_path(dataset_path=\"path/to/an/dgp/dataset\", dataset_format=\"dgp\")\n",
    "# You can also create it using a custom image iterator\n",
    "iterator_distribution = GaussianColorDistribution.from_image_stream(image_stream=iter(some_image_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef589e-2076-42fd-8a32-7c18517df7cf",
   "metadata": {},
   "source": [
    "The color transformation can be calculated between a source and a target distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62397470-1bd5-42cf-906d-4744e58b029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = ColorMatcher.from_distributions(source=source_distribution, target=target_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55015561-8ff0-4a38-bbea-9f2d38b745fe",
   "metadata": {},
   "source": [
    "Both the distributions and the transform can be stored to json and loaded again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e6f5f-545c-4dc1-9899-ace7596f746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_distribution.save_to_json(\"some/json/path.json\")\n",
    "loaded_distribution = GaussianColorDistribution.from_json(\"some/json/path.json\")\n",
    "# Same for the matcher:\n",
    "matcher.save_to_json(\"some/json/path.json\")\n",
    "loaded_matcher = ColorMatcher.from_json(\"some/json/path.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767274a-6742-4f53-a27f-82a3e5b05d8c",
   "metadata": {},
   "source": [
    "To apply the color matcher to an image simply use the matmul operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e622243-c18e-4ad5-9eaa-6ddd6990ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_matched = matcher @ image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6dd0d-ce37-4cd9-b3db-e9b6b5b35689",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "We approximate the color shift of the camera by looking at some example images. This only works if the color shift in the scenes is not too large. It's therefore recommended to exclude tunnels and similar from the statistic calculations. It might be necessary to calculate multiple distributions for different times of day.\n",
    "The method is also not applicable for relighting. Transforming night images to day images or the other way arround shows the limitations:\n",
    "\n",
    "| source | target | transformed |\n",
    "|---|---|---|\n",
    "| ![PDNight](../../_static/color_matcher_pd_night.png) | ![Cityscapes2](../../_static/color_matcher_cityscapes.png) | ![CityscapesNight](../../_static/color_matcher_cityscapes_night.png) |\n",
    "| ![Cityscapes3](../../_static/color_matcher_cityscapes.png) | ![PD Night2](../../_static/color_matcher_pd_night.png) | ![PDNightCityscapes](../../_static/color_matcher_pd_night_cityscapes.png) |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
